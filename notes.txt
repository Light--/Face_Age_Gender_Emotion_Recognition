age, gender model:
    (1) weights.28-3.73.hdf5 (trained on IMDB+WIKI), weights.29-3.76_utk.hdf5 (trained on UTKFace)
        => https://github.com/yu4u/age-gender-estimation
        *準度差不多

face model:
    (1) deploy.prototxt, res10_300x300_ssd_iter_140000.caffemodel
        => https://blog.csdn.net/zhongranxu/article/details/79650387
    (2) haarcascade_frontalface_*.xml, lbpcascade_frontalface_improved.xml
        => https://github.com/opencv/opencv/tree/master/data

emotion model:
    (1) emotion_model.hdf5
        => https://github.com/petercunha/Emotion
    (2) fer2013_mini_XCEPTION.99-0.65.hdf5
        => https://github.com/oarriaga/face_classification/tree/master/trained_models/emotion_models

* 目前最好的 model: my_trained/21/weights.09-3.83.hdf5

-----------------------------------------------------------------------------------------------------------
== GPU 記憶體佔用量 ==
WideResNet: 7G
opconty_shufflnet_v2
    batch size 32: 5.8G
    batch size 48： 5603M
    batch size 64： 5595M

== 主機記憶體佔用量(含其他程式佔用量) ==
opconty_shufflnet_v2
    batch size 48： 16.3G
    batch size 64： 15.7G

== 訓練時間 ==
WideResNet 30 epochs: 11小時
調整 lr，剩 10 epochs： 3小時45分
改用 keras MobileNetV2: 45分
改用 opconty_shufflenet_v2: 50分

== 參數量 ==
WideResNet: 25,381,360
keras MobileNetV2: 2,821,294
opconty_shufflenet_v2: 4,131,490

-----------------------------------------------------------------------------------------------------------
TODO
V) 1. lightweight backbone: mobilenetv2
2. Asian images
3. add emotion images
V) 4. enlarge val data
